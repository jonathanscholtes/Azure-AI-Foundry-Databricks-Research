{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a4c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9c0f3",
   "metadata": {},
   "source": [
    "# Connecting to a Remote MCP Server with Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to connect to a remote MCP Server using **Semantic Kernel's** `MCPStreamableHttpPlugin`. The **Model Context Protocol (MCP)** enables scalable and modular tool integration across distributed systems. \n",
    "\n",
    "<br/>\n",
    "\n",
    "> **Why Use Model Context Protocol (MCP)?**\n",
    ">\n",
    ">MCP allows agents to discover, invoke, and manage tools dynamically across remote servers.  \n",
    ">It promotes modularity, scalability, and separation of concerns, making it easier to maintain and extend AI systems as they grow in complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3f6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent,ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "import asyncio\n",
    "\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"chat\",\n",
    "    deployment_name=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "    base_url=environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=environ[\"AZURE_OPENAI_API_KEY\"] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d34908b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "\n",
      "Which products generated the most revenue?\n",
      "Based on product sales revenue, here is the summary:\n",
      "\n",
      "### Products and Revenue\n",
      "1. **Brake Pad**\n",
      "   - Revenue: $10,796.5\n",
      "   - Category: Braking\n",
      "\n",
      "2. **Oil Filter**\n",
      "   - Revenue: $1,732.8\n",
      "   - Category: Engine\n",
      "\n",
      "3. **Spark Plug**\n",
      "   - Revenue: $1,062.44\n",
      "   - Category: Electrical\n",
      "\n",
      "4. **Alternator**\n",
      "   - No recorded sales in the dataset.\n",
      "\n",
      "5. **Transmission Kit**\n",
      "   - No recorded sales in the dataset.\n",
      "\n",
      "### Most Revenue\n",
      "The **Brake Pad** generated the most revenue of **$10,796.5**, dominating sales performance among all listed products.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Drill down into customer details product with the highest revenue.\n",
      "The product with the highest revenue is **Spark Plug**, belonging to the \"Electrical\" category. Its unit price is $8.0, and its unit cost is $2.0.\n",
      "\n",
      "The customer involved is **NAPA**, which operates in the \"Distributor\" industry, located in the North America (NA) region. Their account manager is **Ellen Garcia**.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Which customer had the highest sales for this product?\n",
      "To determine which customer had the highest sales for the specified product, I need the product's details or ID. Could you share it with me?\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "    \"Which products generated the most revenue?\",\n",
    "    \"Drill down into customer details product with the highest revenue.\",\n",
    "    \"Which customer had the highest sales for this product?\",\n",
    "]\n",
    "\n",
    "thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "async with MCPStreamableHttpPlugin(\n",
    "    name=\"sales\",\n",
    "    url=f\"{environ['MCP_SERVER_URL']}\",\n",
    ") as sales_plugin:\n",
    "\n",
    "    agent = ChatCompletionAgent(\n",
    "        kernel=kernel, \n",
    "        name=\"SalesAgent\", \n",
    "        plugins=[sales_plugin, ]\n",
    "    )\n",
    "\n",
    "\n",
    "    for msg in messages:\n",
    "        print(\"------------------------------------------------\\n\")\n",
    "        print(msg)\n",
    "        response = await agent.get_response(messages=msg, thread=thread)\n",
    "        print(response)\n",
    "        print(\"\\n------------------------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
