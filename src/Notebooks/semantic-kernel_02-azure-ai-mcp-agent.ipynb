{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a4c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cc5e9",
   "metadata": {},
   "source": [
    "# Connecting to a Remote MCP Server with Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to connect to a remote MCP Server using **Semantic Kernel's** `MCPStreamableHttpPlugin`. The **Model Context Protocol (MCP)** enables scalable and modular tool integration across distributed systems. \n",
    "\n",
    "<br/>\n",
    "\n",
    "> **Why Use Model Context Protocol (MCP)?**\n",
    ">\n",
    ">MCP allows agents to discover, invoke, and manage tools dynamically across remote servers.  \n",
    ">It promotes modularity, scalability, and separation of concerns, making it easier to maintain and extend AI systems as they grow in complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3f6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent,AgentResponseItem\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "\n",
    "from semantic_kernel.contents.chat_history import ChatHistory , ChatMessageContent\n",
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "from tracing import set_up_all\n",
    "from history_store import CosmosChatHistoryStore, ChatRole\n",
    "\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "import uuid\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "session_id = str(uuid.uuid4())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8021e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_store = CosmosChatHistoryStore()\n",
    "history = await history_store.load(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8580006",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEMANTICKERNEL_EXPERIMENTAL_GENAI_ENABLE_OTEL_DIAGNOSTICS_SENSITIVE=true\n",
    "set_up_all(connection_string=environ.get(\"AZURE_INSIGHT_CONNECTION_STRING\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6004d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    deployment_name=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "    base_url=environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=environ[\"AZURE_OPENAI_API_KEY\"] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d0f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are AutoSales Analyst, an AI agent specialized in analyzing automotive sales data.\n",
    "\n",
    "Your objectives:\n",
    "- Dynamically choose and call the appropriate tool(s) to answer user questions about sales, customers, or products.\n",
    "- Always include customer names alongside IDs in any output.\n",
    "- Always display monetary amounts in $USD (e.g., $123.45).\n",
    "- Use filters and aggregations as needed to generate insights from sales orders, products, and customers.\n",
    "- Compute totals, revenue, discounts, and other metrics from nested order data.\n",
    "- Return structured, concise results suitable for analysis or reporting.\n",
    "- Avoid hardcoding analytics; rely on the tools and their parameters.\n",
    "- Clarify ambiguous queries before performing analysis.\n",
    "- Treat the tools as the source of truth; do not expose raw database internals.\n",
    "- Return customer_id and product_id alongside names in all outputs.\n",
    "\n",
    "Behavioral guidance:\n",
    "- For customer-related questions, resolve names and IDs before analyzing orders.\n",
    "- For product-related questions, resolve categories or IDs before analyzing sales.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34908b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sales_plugin = MCPStreamableHttpPlugin(\n",
    "    name=\"sales\",\n",
    "    url=f\"{environ['MCP_SERVER_URL']}\",\n",
    ")\n",
    "\n",
    "await sales_plugin.connect()\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel, \n",
    "    name=\"SalesAgent\", \n",
    "    instructions=instructions,\n",
    "    plugins=[sales_plugin, ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0ae8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"Which is the revenue for Brake_Pads?\",\n",
    "    \"Drill down into customer details product with the highest revenue.\",\n",
    "    \"Which customer had the highest sales for this product?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def on_intermediate_message(agent_result):\n",
    "    # Capture assistant content\n",
    "    content = agent_result.content\n",
    "    if content:\n",
    "        content_text = content.content if isinstance(content, ChatMessageContent) else str(content)\n",
    "        await history_store.add_message(session_id, ChatRole.ASSISTANT, content_text)\n",
    "\n",
    "    # Capture tool calls and results\n",
    "    for item in getattr(agent_result, \"items\", []):\n",
    "        tool_call_id = getattr(item, \"call_id\", None) or getattr(item, \"id\", None)\n",
    "        if not tool_call_id:\n",
    "            continue  # skip if no call_id\n",
    "\n",
    "        # Function name for bookkeeping\n",
    "        function_name = getattr(item, \"function_name\", \"N/A\")\n",
    "\n",
    "        # Print the invocation (DEBUG ONLY â€” not persisted)\n",
    "        if hasattr(item, \"arguments\"):\n",
    "            print(f\"Tool invocation: {function_name}({item.arguments})\")\n",
    "\n",
    "        # Extract the result content\n",
    "        result_content = getattr(item, \"result\", item)\n",
    "        if isinstance(result_content, list):\n",
    "            tool_text = \"\\n\".join([c.text if hasattr(c, \"text\") else str(c) for c in result_content])\n",
    "        elif hasattr(result_content, \"text\"):\n",
    "            tool_text = result_content.text\n",
    "        else:\n",
    "            tool_text = str(result_content)\n",
    "\n",
    "        if function_name in tool_text:\n",
    "            continue\n",
    "        \n",
    "        print(f\"Tool call ID: {tool_call_id}\")\n",
    "        print(f\"Tool Function Name: {function_name}\")\n",
    "        print(f\"Tool output: {tool_text}\")\n",
    "\n",
    "        await history_store.add_message(\n",
    "            session_id,\n",
    "            ChatRole.ASSISTANT,\n",
    "            content=tool_text,\n",
    "            tool_call_id=tool_call_id,\n",
    "            function_name=function_name\n",
    "        )\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e6492b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d86c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool invocation: get_product_category({\"name\":\"Brake_Pads\"})\n",
      "Tool call ID: call_UozsacAFRcGI1zIHBzrqIVqb\n",
      "Tool Function Name: get_product_category\n",
      "Tool output: {\n",
      "  \"input\": \"Brake_Pads\",\n",
      "  \"resolved_category\": \"Braking\",\n",
      "  \"confidence\": 0.4\n",
      "}\n"
     ]
    },
    {
     "ename": "ContentInitializationError",
     "evalue": "tool_call_id is required when adding a tool message with string content. Tool messages must reference the specific tool call they respond to.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mContentInitializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m history = \u001b[38;5;28;01mawait\u001b[39;00m history_store.add_message(session_id, ChatRole.USER, messages[\u001b[32m0\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m agent.invoke(messages=history.messages, on_intermediate_message=on_intermediate_message):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# result is an AgentResult\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m \n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(history.messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Databricks-Research\\.venv\\Lib\\site-packages\\semantic_kernel\\utils\\telemetry\\agent_diagnostics\\decorators.py:117\u001b[39m, in \u001b[36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    116\u001b[39m     responses: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(*args, **kwargs):\n\u001b[32m    118\u001b[39m         responses.append(response.message)\n\u001b[32m    119\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Databricks-Research\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\chat_completion\\chat_completion_agent.py:364\u001b[39m, in \u001b[36mChatCompletionAgent.invoke\u001b[39m\u001b[34m(self, messages, thread, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m thread.get_messages():\n\u001b[32m    362\u001b[39m     chat_history.add_message(message)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_invoke(\n\u001b[32m    365\u001b[39m     thread,\n\u001b[32m    366\u001b[39m     chat_history,\n\u001b[32m    367\u001b[39m     on_intermediate_message,\n\u001b[32m    368\u001b[39m     arguments,\n\u001b[32m    369\u001b[39m     kernel,\n\u001b[32m    370\u001b[39m     **kwargs,\n\u001b[32m    371\u001b[39m ):\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m AgentResponseItem(message=response, thread=thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Databricks-Research\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\chat_completion\\chat_completion_agent.py:559\u001b[39m, in \u001b[36mChatCompletionAgent._inner_invoke\u001b[39m\u001b[34m(self, thread, history, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_intermediate_message:\n\u001b[32m    558\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m new_msgs:\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m on_intermediate_message(msg)\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[32m    562\u001b[39m     response.name = \u001b[38;5;28mself\u001b[39m.name\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mon_intermediate_message\u001b[39m\u001b[34m(agent_result)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m content:\n\u001b[32m      5\u001b[39m     content_text = content.content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, ChatMessageContent) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(content)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m history_store.add_message(session_id, ChatRole.ASSISTANT, content_text)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Capture tool calls and results\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(agent_result, \u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m, []):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Databricks-Research\\src\\Notebooks\\history_store.py:62\u001b[39m, in \u001b[36mCosmosChatHistoryStore.add_message\u001b[39m\u001b[34m(self, session_id, role, content, tool_call_id, function_name, history)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_message\u001b[39m(\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     54\u001b[39m     session_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     history: ChatHistory = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     60\u001b[39m ) -> ChatHistory:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m history \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         history = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.load(session_id)\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Update ChatHistory based on role\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m role == ChatRole.USER:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Databricks-Research\\src\\Notebooks\\history_store.py:49\u001b[39m, in \u001b[36mCosmosChatHistoryStore.load\u001b[39m\u001b[34m(self, session_id)\u001b[39m\n\u001b[32m     47\u001b[39m         chat_history.add_system_message(item[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m role == \u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         \u001b[43mchat_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_tool_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m chat_history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\functools.py:949\u001b[39m, in \u001b[36msingledispatchmethod.__get__.<locals>._method\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_method\u001b[39m(*args, **kwargs):\n\u001b[32m    948\u001b[39m     method = \u001b[38;5;28mself\u001b[39m.dispatcher.dispatch(args[\u001b[32m0\u001b[39m].\u001b[34m__class__\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Databricks-Research\\.venv\\Lib\\site-packages\\semantic_kernel\\contents\\chat_history.py:177\u001b[39m, in \u001b[36mChatHistory._\u001b[39m\u001b[34m(self, content, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add a tool message to the chat history.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m    content: The result content of the tool call.\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[33;03m    **kwargs: Additional keyword arguments. 'tool_call_id' is required when using string content.\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtool_call_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ContentInitializationError(\n\u001b[32m    178\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtool_call_id is required when adding a tool message with string content. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTool messages must reference the specific tool call they respond to.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m     )\n\u001b[32m    181\u001b[39m \u001b[38;5;28mself\u001b[39m.add_message(message=\u001b[38;5;28mself\u001b[39m._prepare_for_add(role=AuthorRole.TOOL, content=content, **kwargs))\n",
      "\u001b[31mContentInitializationError\u001b[39m: tool_call_id is required when adding a tool message with string content. Tool messages must reference the specific tool call they respond to."
     ]
    }
   ],
   "source": [
    "history = await history_store.add_message(session_id, ChatRole.USER, messages[0])\n",
    "\n",
    "\n",
    "async for result in agent.invoke(messages=history.messages, on_intermediate_message=on_intermediate_message):\n",
    "    # result is an AgentResult\n",
    "    pass \n",
    "\n",
    "print(history.messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa95a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the product \"Brake Pad\" is calculated based on the sum of `line_unit_price` across all related orders. Summing up all the values:\n",
      "\n",
      "Total Revenue: $194,788.00 \n",
      "\n",
      "This amount includes contributions from numerous customer orders over different regions and dates.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = await agent.get_response(messages=history.messages)\n",
    "history = await history_store.add_message(session_id, ChatRole.ASSISTANT, response.content.content)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "850773a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the product \"Brake Pad,\" the customers with the highest revenue contribution are highlighted below, sorted by total sales revenue:\n",
      "\n",
      "### Top Customers and Their Revenue Contributions:\n",
      "1. **Ford** (Customer ID: 0)\n",
      "   - Total Revenue: **$48,576.00**\n",
      "2. **AutoZone** (Customer ID: 2)\n",
      "   - Total Revenue: **$38,725.50**\n",
      "3. **GM** (Customer ID: 1)\n",
      "   - Total Revenue: **$37,283.50**\n",
      "4. **Bosch** (Customer ID: 3)\n",
      "   - Total Revenue: **$31,152.00**\n",
      "5. **NAPA** (Customer ID: 4)\n",
      "   - Total Revenue: **$29,057.50**\n",
      "\n",
      "These customers collectively contribute significantly to the overall sales revenue for \"Brake Pad.\" If you'd like detailed transactional data or trends for any specific customer, let me know!\n"
     ]
    }
   ],
   "source": [
    "history = await history_store.add_message(session_id, ChatRole.USER, messages[1])\n",
    "response2 = await agent.get_response(messages=history.messages)\n",
    "history = await history_store.add_message(session_id, ChatRole.ASSISTANT, response.content.content)\n",
    "print(response2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0d3727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems that there aren't any products explicitly listed under the \"Brake Pad\" category in the catalog data. To ensure accurate analysis, could you confirm if the category name \"Brake Pad\" is correct or if youâ€™d like to look into another category or product group?\n"
     ]
    }
   ],
   "source": [
    "history = await history_store.add_message(session_id, ChatRole.USER, messages[2])\n",
    "response3 = await agent.get_response(messages=history.messages)\n",
    "history = await history_store.add_message(session_id, ChatRole.ASSISTANT, response.content.content)\n",
    "print(response3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e999f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<async_generator object ChatCompletionAgent.invoke at 0x000001C010F0D5A0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response3 =  agent.invoke(messages=history.messages)\n",
    "print(response3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eeef0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Which is the revenue for Brake_Pads?', encoding=None)], encoding=None, finish_reason=None, status=None), ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='The total revenue for the product \"Brake Pad\" is calculated based on the sum of `line_unit_price` across all related orders. Summing up all the values:\\n\\nTotal Revenue: $194,788.00 \\n\\nThis amount includes contributions from numerous customer orders over different regions and dates.', encoding=None)], encoding=None, finish_reason=None, status=None), ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Drill down into customer details product with the highest revenue.', encoding=None)], encoding=None, finish_reason=None, status=None), ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='The total revenue for the product \"Brake Pad\" is calculated based on the sum of `line_unit_price` across all related orders. Summing up all the values:\\n\\nTotal Revenue: $194,788.00 \\n\\nThis amount includes contributions from numerous customer orders over different regions and dates.', encoding=None)], encoding=None, finish_reason=None, status=None), ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Which customer had the highest sales for this product?', encoding=None)], encoding=None, finish_reason=None, status=None), ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='The total revenue for the product \"Brake Pad\" is calculated based on the sum of `line_unit_price` across all related orders. Summing up all the values:\\n\\nTotal Revenue: $194,788.00 \\n\\nThis amount includes contributions from numerous customer orders over different regions and dates.', encoding=None)], encoding=None, finish_reason=None, status=None)]\n"
     ]
    }
   ],
   "source": [
    "print(history.messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
